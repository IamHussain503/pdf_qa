from django.shortcuts import render, redirect
from django.core.files.storage import default_storage
from .models import UploadedDocument
import openai
from pymongo import MongoClient
from openai import OpenAI, AssistantEventHandler
from typing_extensions import override


# Initialize the OpenAI client
#api key here

# Define the event handler for streaming responses
class EventHandler(AssistantEventHandler):
    @override
    def on_text_created(self, text) -> None:
        print(f"\nassistant > {text}", end="", flush=True)

    @override
    def on_tool_call_created(self, tool_call):
        print(f"\nassistant > Tool call created: {tool_call.type}\n", flush=True)

    @override
    def on_message_done(self, message) -> None:
        message_content = message.content[0].text
        annotations = message_content.annotations
        citations = []
        for index, annotation in enumerate(annotations):
            message_content.value = message_content.value.replace(
                annotation.text, f"[{index}]"
            )
            if file_citation := getattr(annotation, "file_citation", None):
                cited_file = openai_client.files.retrieve(file_citation.file_id)
                citations.append(f"[{index}] {cited_file.filename}")

        print("\nMessage content: ", message_content.value)
        print("Citations: ", "\n".join(citations))


# Initialize the assistant
assistant = openai_client.beta.assistants.create(
    name="PDF File QA Assistant",
    instructions="You are an assistant who answers questions based on the content of uploaded PDF files.",
    model="gpt-4o",
    tools=[{"type": "file_search"}]
)

# Function to handle the file upload and create the vector store
from django.shortcuts import render, redirect
from django.core.files.storage import default_storage
from .models import UploadedDocument
import openai
from pymongo import MongoClient
import logging

# Set up logging
logger = logging.getLogger(__name__)

# Initialize MongoDB client (already configured in settings.py, this will reuse the same connection)
client = MongoClient('mongodb+srv://zaidali:IUzvdpQZ7MMaixB8@cluster0.qmehy3e.mongodb.net/Todo?retryWrites=true&w=majority')
db = client['Todo']
uploaded_docs_collection = db['home_uploadeddocument']  # Assuming collection name is 'home_uploadeddocument'


from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from django.http import JsonResponse
from .models import UploadedDocument
import openai


class UploadDocumentAPI(APIView):
    """API to upload a PDF document and create a vector store."""

    def post(self, request):
        if 'pdf_file' not in request.FILES:
            return Response({"error": "No PDF file uploaded."}, status=status.HTTP_400_BAD_REQUEST)

        pdf_file = request.FILES['pdf_file']  # Get the uploaded PDF file
        file_name = pdf_file.name  # Get the file name

        # Create a vector store and upload the PDF content
        vector_store = upload_file_and_create_vector_store(pdf_file, file_name)

        # Save the uploaded file information in MongoDB using Django ORM
        document = UploadedDocument.objects.create(
            file_name=file_name,
            vector_store_id=vector_store.id
        )

        return Response({
            "file_name": document.file_name,
            "vector_store_id": document.vector_store_id
        }, status=status.HTTP_201_CREATED)


class RetrieveDocumentAPI(APIView):
    """API to retrieve file_name and vector_store_id for all uploaded documents."""

    def get(self, request):
        documents = UploadedDocument.objects.all()
        documents_list = [
            {"file_name": doc.file_name, "vector_store_id": doc.vector_store_id}
            for doc in documents
        ]
        return JsonResponse(documents_list, safe=False)


class AskQuestionAPI(APIView):
    """API to answer questions using the vector store."""

    def post(self, request):
        question = request.data.get('question', None)
        vector_store_id = request.data.get('vector_store_id', None)

        if not question or not vector_store_id:
            return Response({"error": "Both 'question' and 'vector_store_id' are required."}, status=status.HTTP_400_BAD_REQUEST)

        # Get the answer from the vector store
        answer = ask_question_with_file_search(question, vector_store_id)
        
        return Response({"question": question, "answer": answer}, status=status.HTTP_200_OK)




def upload_pdf_page(request):
    """Render the PDF upload page and handle file uploads and question submissions."""
    uploaded_files = UploadedDocument.objects.all()  # Fetch all uploaded PDFs using Django ORM
    answer = None
    question = None

    if request.method == 'POST':
        if 'pdf_file' in request.FILES:
            try:
                # Handle PDF file upload
                pdf_file = request.FILES['pdf_file']
                file_name = pdf_file.name

                logger.info(f"Received file: {file_name}")

                # Create a vector store and upload the PDF content
                vector_store = upload_file_and_create_vector_store(pdf_file, file_name)

                # Use pymongo to save the data directly to MongoDB
                uploaded_docs_collection.insert_one({
                    'file_name': file_name,
                    'vector_store_id': vector_store.id
                })
                logger.info(f"File '{file_name}' with vector store ID '{vector_store.id}' inserted successfully into MongoDB.")

                return redirect('upload_pdf_page')  # Redirect to avoid form resubmission

            except Exception as e:
                logger.error(f"Error during file upload: {str(e)}", exc_info=True)
                return render(request, 'upload_pdf.html', {
                    'error_message': 'There was an error uploading the file. Please try again.'
                })

        elif 'uploaded_file' in request.POST and 'question' in request.POST:
            # Handle question submission
            uploaded_file_id = request.POST['uploaded_file']
            question = request.POST['question']
            uploaded_file = UploadedDocument.objects.get(id=uploaded_file_id)

            if uploaded_file:
                logger.info(f"Question '{question}' asked for file '{uploaded_file.file_name}'")
                answer = ask_question_with_file_search(question, uploaded_file.vector_store_id)

    return render(request, 'upload_pdf.html', {
        'uploaded_files': uploaded_files,
        'answer': answer,  # Pass the captured answer to the template
        'question': question
    })

def upload_file_and_create_vector_store(pdf_file, vector_store_name: str):
    """Create a vector store and upload the file content."""
    if isinstance(pdf_file, str):
        raise ValueError("Expected a file-like object, but got a string instead.")

    vector_store = openai_client.beta.vector_stores.create(name=vector_store_name)

    try:
        pdf_file.seek(0)
    except AttributeError as e:
        raise ValueError(f"pdf_file is not a file-like object: {e}")

    file_content = pdf_file.read()

    file_batch = openai_client.beta.vector_stores.file_batches.upload_and_poll(
        vector_store_id=vector_store.id,
        files=[(pdf_file.name, file_content)]
    )

    logger.info(f"Vector store created with ID: {vector_store.id}")
    logger.info(f"File batch status: {file_batch.status}")

    return vector_store


def ask_question_with_file_search(question: str, vector_store_id: str):
    """Ask a question using the vector store and get a streaming response."""
    # Create a thread with the question and reference the vector store
    thread = openai_client.beta.threads.create(
        messages=[
            {
                "role": "user",
                "content": question
            }
        ],
        tool_resources={
            "file_search": {
                "vector_store_ids": [vector_store_id]
            }
        }
    )

    # Run the assistant and stream the response using the event handler
    event_handler = EventHandler()

    print(f"Question '{question}' is being asked with vector store ID '{vector_store_id}'...")

    # The context manager handles the stream properly
    with openai_client.beta.threads.runs.stream(
        thread_id=thread.id,
        assistant_id=assistant.id,
        instructions="Please address the user as Jane Doe. The user has a premium account.",
        event_handler=event_handler,
    ) as stream:
        # This will iterate through the stream automatically
        stream.until_done()

    print("Response streamed, check console output.")

    # Return the full streamed response
    return event_handler.response
